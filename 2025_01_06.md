# Oxide and Friends: January 6th, 2025

## Predictions 2025

We've been hosting a live show weekly on Mondays at 5p for about an hour,
and recording them all; here is
[the recording](https://youtu.be/-pk6VokHpGY).

In addition to
[Bryan Cantrill](https://bsky.app/profile/bcantrill.bsky.social) and
[Adam Leventhal](https://bsky.app/profile/ahl.bsky.social),
our guest were
[Simon Willison](https://fedi.simonwillison.net/@simon),
Mike Cafarella,
[Steve Tuck](https://bsky.app/profile/sdtuck.bsky.social),
and
[Steve Klabnik](https://bsky.app/profile/steveklabnik.com).

<table>
<tr>
<th>Futurist</th>
<th>1 year</th>
<th>3 year</th>
<th>6 year</th>
</tr>

<tr>
<td>
  <a href="https://steveklabnik.com">Steve</a>
</td>
<td>
  Congestion pricing in NYC will be an unambiguous success. It will still exist and sentiment will be positive.
</td>
<td>
  Some government contracts will require a memory safety roadmap included in the procurement process.
</td>
<td>
  AI will no longer be the hottest sector of investment in Silicon Valley, in the same way that AI replaced Web3 as such.
</td>
</tr>

<tr>
<td>
Steve Tuck
</td>
<td>
AMD acquires a software startup for over $1B to (try to) solve their software problems 
</td>
<td>
Fox Rental Car is bigger than Hertz Rental
</td>
<td>
Intel is out of the Foundry business 
</td>
</tr>

<tr>
<td>
Adam
</td>
<td>
Web3 is back (baby!) both as a term and an investment focus for VC. Crypto hype is back in force.
</td>
<td>
Chips crisis--brought on by geopolitics, tarriffs, natural disaster, etc. leading to shortages and a small set of companies who can get the choicest processors (and processes) (Oxide is among them).
</td>
<td>
AI is mostly done on even more specialized hardware that doesn't resemble GPUs (e.g. not CUDA). This enables a diversity of vendors.
</td>
</tr>

<tr>
<td>
Bryan
</td>
<td>
2025 is the Year of AI Efficiency: era of 10X YoY pretraining cluster
growth is over, with cluster flattening being treated with various 
euphemisms ("pause", "correction", "consolidation", etc.)
Emphasis swings to training with less resources (DeepSeek) and test-time compute.
<hr>
Blackwell struggles:  thermal issues, yield issues, reliability issues,
pricepoint, changing market conditions.  H100/H200 thrive.
<hr>
Intel's CEO search is an unmitigated disaster, with warring constiuencies
unable to agree; the year ends with the co-CEOs still in place
</td>
<td>
Cybertruck is no longer being manufactured
<hr>
After much tumult, Intel Foundry Services has been spun out of Intel -- and does not
bear the Intel name.  It has been purchased for $1 by a deep-pocketed maverick.
<hr>
A new product/service has used LLMs to completely revolutionize podcast
search/listening
</td>
<td>
Secondary education has been revolutionized by LLMs/AI
<hr>
Postsecondary degrees in CS (and related) are in freefall:  below 70k/year
and dropping (~2015 levels)
<hr>
</td>
</tr>
</table>

Join us live to drop your predictions and/or make a PR adding your predictions to this table. We'll accept predictions through January 2025.

<table>
<tr>
<th>Futurist</th>
<th>1 year</th>
<th>3 year</th>
<th>6 year</th>
</tr>
<tr>
<td>
Fable Tales <a href="https://bsky.app/profile/fable-computers.bsky.social">bsky</a>
</td>
<td>
TSMC's arizona fab will be oversubscribed by end of 2025.
</td>
<td>
We will have conclusively decided that current approaches to AI (i.e. LLMS) will not produce AGI or ASI.
</td>
<td>
CPU/GPU on a chip ala apple silicon is the norm in all consumer computing, and has somewhat high enterprise/server penetration. Many applications that today do not take advantage of GPU availability are offloading work to them.
</td>
</tr>

<tr>
<td>
Joe Thompson
</td>
<td>
One of the major AI companies will be forced to shut down either due to running out of investment cash or due to a data breach of such severity they're basically forced to close up shop.
</td>
<td>
The tension between open source and "community source" will finally break out into the open with an OSI-style organization formed to classify and endorse licenses that allow permissive access to source but restrict its use in various ways.
</td>
<td>
There will be at least one single-day loss of a trillion dollars in market cap of a major publicly-traded tech company.

Kelsey Hightower will be acclaimed CNCF God-Emperor For Life.

I will finally understand how git works.
</td>
</tr>

<tr>
<td>
  <a href="https://krisshamloo.com">Kris</a>
</td>
<td>
  Mojo hits top 25 in TIOBE Index.
</td>
<td>
  Handheld gaming dominates, Switch 2 and Steam Deck 2 lead the shift from flagship consoles to flagship portables. Swift-5-to-6 considered a Python-2-to-3 failure writ small.
</td>
<td>
  Waymo’s success balances out Google’s ongoing decline. Household cleaning robots beyond vacuums are commonplace.
</td>
</tr>
  

<tr>
<td>
Ellie (bsky: https://bsky.app/profile/ellie.fm)
</td>
<td>
We crack the Tbps barrier in the enterprise for a single ethernet link (currently 800Gbps)

Hardware for CXL will enter GA, software won't be there to take advantage quite yet

RISC-V enters the datacenter via Tenstorrent in the form of "AI acceleration cards". Nobody figures out how the hell to use them for about 2-3 years though.
</td>
<td>
25Gbps over CAT7/CAT8 happens, meaning that we'll see more consumer hardware supporting it as a step up from 10GbE.
  
CXL is used in the building of a HPC cluster, supplementing InfiniBand / Ethernet. Software support starts picking up, people start figuring out how to use it

Someone outside of AMD/NVIDIA/AWS/Azure finally figures out how to properly make use of DPUs, and we see proper software support & adoption. Could be in the form of CNIs (for Kubernetes), whatnot.

We see a rise in more exotic cooling solutions in the datacenter (mineral oil immersion, water-based, maybe even liquid nitrogen?) due to ever-increasing power requirements from GPUs + x86 servers

OCP racks will enter GA, meaning blind-mated 48VDC power backplanes for all, albeit in a vastly different form factor from regular 42U racks.

K8s will continue to remain supreme and eat up more market share from VMware's remains

It becomes seamless to transition off of x86 -> ARM, thanks to a new compatibility layer that {Amazon, Ampere, NVIDIA, etc} developed, very similar to Rosetta 2 (Apple).
</td>
<td>
GPUs are entirely racked separately from compute blades in datacenters, connected over CXL fabric (rack-to-rack).
  
ARM market-share in the datacenter increases dramatically, thanks to better thermals + performance compared to x86, as well as the aforementioned compatibility layer.
</td>
</tr>

<tr>
<td>
<a href="https://bsky.app/profile/triangulator.org">Kevin Webb</a>
</td>
<td>
Someone releases a non-chat, task-specific deep learning application that goes viral/breaks through the noise on AGI/"One Model to Rule Them All" narrative pushed by OpenAI et al.
</td>
<td>
Mainstream journalism discovers that most folks working in the industry are building practical task-specific deep learning applications, and that chat-based AGI is a marketing ploy, not a technology.

Inference costs for GPT-oÆ-12, and lobbying for deregulation of nuclear energy bankrupts OpenAI despite attempts to charge 100x premium on GPU compute.  
</td>
<td>
Nvidia solves driver installation challenges stymying AI industry. Over 100 AI infrastructure startups fold as their business model collapses.
</td>
</tr>

</table>

If we got something wrong or missed something, please file a PR!
Our next show will likely be on Monday at 5p Pacific Time on our Discord
server; stay tuned to our Mastodon feeds for details, or [subscribe to this
calendar](https://calendar.google.com/calendar/ical/c_318925f4185aa71c4524d0d6127f31058c9e21f29f017d48a0fca6f564969cd0%40group.calendar.google.com/public/basic.ics).
We'd love to have you join us, as we always love to hear from new speakers!

