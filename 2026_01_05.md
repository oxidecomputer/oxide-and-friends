# Oxide and Friends: January 5th, 2026

## Predictions 2026!!

We've been hosting a live show weekly on Mondays at 5p for about an hour,
and recording them all; here is
[the recording]().

In addition to
[Bryan Cantrill](https://bsky.app/profile/bcantrill.bsky.social) and
[Adam Leventhal](https://bsky.app/profile/ahl.bsky.social),
speakers included
[Simon Willison](https://simonwillison.net:),
and [YY]().
(Did we miss your name and/or get it wrong? Drop a PR!)

<table>
<tr>
<th>Futurist</th>
<th>1 year</th>
<th>3 year</th>
<th>6 year</th>
</tr>

<tr>
<td>
  <a href="https://bsky.app/profile/ahl.bsky.social">Adam</a>
</td>
<td>
TBD
</td>
<td>
TBD
</td>
<td>
TBD
</td>
</tr>

<tr>
<td>
  <a href="https://simonwillison.net/">Simon</a>
</td>
<td>
    The AI for programming holdouts are going to have a nasty shock
    <hr>
    We're going to solve sandboxing
    <hr>
    Our own challenger disaster with respect to coding agent security - see <a href="https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/">the Normalization of Deviance in AI</a> by Johann Rehberger
</td>
<td>
    Something that seems impossible for a coding agent to build today - like a full working web browser - won't just be built by coding agents, it will be unsurprising
    <hr>
    We will find out if the Jevons paradox saves our careers as software engineers or not
</td>
<td>
    The number of people employed to type code into computers will drop to almost nothing - it will be like punch card operators. Those of us who write code today will have very different jobs that still build software and take advantage of our previous coding experience.
</td>
</tr>
<td>
  <a href="https://steveklabnik.com">Steve</a>
</td>
<td>
  Agent Orchestration will still be a hot topic. It'll be partially, but not entirely, solved.

  Updated with some more rigour: We won't have a "kubernetes for agents" just yet.
</td>
<td>
  Using AI tools when writing software professionally will be considered something closer to using autocomplete or syntax highlighting than something controversial or exceptional.
</td>
<td>
  AI will not have caused the total collapse of our economic and governmental systems.
</td>
</tr>

</table>

Join us live to drop your predictions and/or make a PR adding your predictions to this table. We'll accept predictions through January 2026.

<table>
<tr>
<th>Futurist</th>
<th>1 year</th>
<th>3 year</th>
<th>6 year</th>
</tr>

<tr>
<td>
  <a href="https://justin.azoff.dev">@JustinAzoff</a>
</td>
<td>
LLMs being able to write code based on specifications and make test suites pass will cause more projects to document how they are supposed to work.  We've already seen people writing more in order to make llms work better, but the same writing also benefits humans.  CLAUDE.MD -> good documentation for how to work on a project
</td>
<td>
An autonomous robot {humanoid, dog, espresso machine} will murder someone and the legal system will struggle with how to assign blame.
</td>
<td>
Less a prediction, but I hope models become fully open and reproducable.  There is a lot of software being built on top of closed models.  If you can't retrain the model (at any cost) you won't own anything.
</td>
</tr>
  
</table>

If we got something wrong or missed something, please file a PR!
Our next show will likely be on Monday at 5p Pacific Time on our Discord
server; stay tuned to our Mastodon feeds for details, or [subscribe to this
calendar](https://calendar.google.com/calendar/ical/c_318925f4185aa71c4524d0d6127f31058c9e21f29f017d48a0fca6f564969cd0%40group.calendar.google.com/public/basic.ics).
We'd love to have you join us, as we always love to hear from new speakers
